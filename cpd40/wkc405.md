# Deploying Watson Knowledge Catalog 4.0.5 using Online Install

## Topics

- [ ] Deployment Planning
- [ ] Setup Bastion Host
- [ ] OpenShift Cluster and Node settings
- [ ] Project creation and NamespaceScope
- [ ] Configuring cluster pull images
- [ ] Custom Security Context Constraints
- [ ] Create IBM Operator Catalog source
- [ ] Installing IBM Cloud Pak foundation services
- [ ] Installing Cloud Pak for Data platform
- [ ] Installing Watson Knowledge Catalog
- [ ] WKC post-installation tasks
- [ ] Installing license server


***
#### 1.0  Deployment planning
***

#### Requirements

- Sizing the Cluster
  https://app.ibmsalesconfigurator.com
  
- OpenShift 4.6.30+ or 4.8.x

- Cluster Compute Requirement
  - [ ] Minimum 3 compute nodes
  - [ ] Each node should be of minimum 16core, 64GB RAM and 200GB storage
  - [ ] Total Compute requirement will be calculated based on the number of services and user workload. IBM Team will help size the cluster compute requirements. 
  - [ ] Minimum Compute requirement for installation: 48 Core, 196 GB
  - [ ] OpenShift nodes should meet the configuration requirements for CPD services

- Cloud Pak for Data 4.0.5 Services
  - [ ] Cloud Pak Foundational Service
  - [ ] Cloud Pak for Data - Control Plane
  - [ ] Watson Knowledge Catalog and its bundle

- Networking Internet access to Mirror IBM image registries
  - [ ] docker.io/ibmcom
  - [ ] quay.io/opencloudio
  - [ ] cp.icr.io/cp 
  - [ ] icr.io/cpopen
  - [ ] https://github.com
  
- Networking Internet access to download IBM installer and cases:
  - [ ] https://github.com/IBM/cloud-pak-cli/releases/download
  - [ ] https://github.com/IBM/cloud-pak/raw/master/repo/case
- Storage
  - [ ] Persistent Storage 1 TB
  - [ ] Private Registry Storage 500 GB (example, Artifactory)
- License
  - [ ] IBM Cloud Pak for Data Standard/Enterprise license
  - [ ] Access to IBM Entitlement Key (myibm.ibm.com)
- User Permissions
  - [ ] OpenShift Administrator ( Cluster preparation )
  - [ ] Cloud Pak for Data administrator ( WKC Installation )
  - [ ] Read/Write permission to Artifactory Registry 
- Bastion Host
   - [ ] RHEL 8x, 500GB disk
   - [ ] Skopeo 1.x
   - [ ] python 3.x
   - [ ] pyyaml, jq

***
#### 2.0 Setup Bastion Host
***


* [ ] Namespaces and Deployment configurations

```
export IBM_COMMON_SERVICE=cpd-common-services  # Project namespace for IBM Foundational services operators
# export CPD_OPERATORS=cpd-common-services     # Project namespace for Cloud Pak for Data Operators
export CPD_INSTANCE=cpd                        # Project namespace for Cloud Pak for Data Install
export STORAGE_TYPE=ocs                        # Specify the type of storage to use, such as ocs , nfs or portworx values nfs, ocs, portworx
export CPD_LICENSE=Enterprise                  # license: Enterprise|Standard  Specify the Cloud Pak for Data license you purchased
export STORAGE_CLASS=ocs-storagecluster-cephfs        # Replace with the name of a RWX storage class
export ZEN_METADB=ocs-storagecluster-ceph-rbd          # (Recommended) Replace with the name of a RWO storage class

# Entitlement and Access tokens
export REGISTRY_USER=cp 
export REGISTRY_PASSWORD=<entitlement-key>      # Cloud Pak for Data Entitlement key from myibm.com 
export REGISTRY_SERVER=cp.icr.io

export PRIVATE_REGISTRY=<registry url>          
export PRIVATE_REGISTRY_USER=<admin>
export PRIVATE_REGISTRY_PASSWORD=<adminpass>

export CASE_REPO_PATH=https://github.com/IBM/cloud-pak/raw/master/repo/case
export CASECTL_RESOLVE_DEPENDENCIES=false                         # This required for ibm-cp-datacore
export USE_SKOPEO=true

export HOMEDIR=/root/cpd405
export OFFLINEDIR=${HOMEDIR}/offline/cpd
export OFFLINEDIR_CPFS=${HOMEDIR}/offline/cpfs
export OFFLINEDIR_WA=${HOMEDIR}/offline/wa

mkdir -p  ${OFFLINEDIR}
mkdir -p  ${OFFLINEDIR_CPFS}
mkdir -p  ${OFFLINEDIR_WA}
cd ${HOMEDIR}

```

* [ ] Download Installer

Prerequisite

- OpenShift CLI	Required to interact with your Red Hat OpenShift Container Platform cluster.
- IBM Cloud Pak CLI (cloudctl)	Required to download images from the IBM Entitled Registry.
- httpd-tools	Required to run the IBM Cloud Pak CLI (cloudctl).
- skopeo Version 1.2.0 or later	Required to run the IBM Cloud Pak CLI (cloudctl).

```
# Skopeo 1.2.x version is required
sudo yum install -y httpd-tools podman ca-certificates openssl skopeo jq bind-utils git

# Python3 is required
yum install -y python3
alternatives --set python /usr/bin/python3
pip3 install pyyaml


# Cloud Pak Installer
wget https://github.com/IBM/cloud-pak-cli/releases/download/v3.12.1/cloudctl-linux-amd64.tar.gz

tar -xf cloudctl-linux-amd64.tar.gz
cp cloudctl-linux-amd64 /usr/bin/cloudctl
cloudctl version

# OpenShift client (if you don't have latest oc client)
wget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.8.26/openshift-client-linux-4.8.26.tar.gz
tar xvf openshift-client-linux-4.8.26.tar.gz
cp oc /usr/bin
cp kubectl /usr/bin

oc version

```

***
#### 3.0 Catalog Source
***
[Creating catalog sources that pull specific versions of images from the IBM Entitled Registry](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=ccs-creating-catalog-sources-that-pull-specific-versions-images-from-entitled-registry)

#### Download CASE Packages

```
# Download the IBM Cloud Pak for Data platform operator CASE package
cloudctl case save \
--repo ${CASE_REPO_PATH} \
--case ibm-cp-datacore \
--version 2.0.10 \
--outputdir ${OFFLINEDIR} \
--no-dependency

# IBM Cloud Pak foundational services
cloudctl case save \
--repo ${CASE_REPO_PATH} \
--case ibm-cp-common-services \
--version 1.10.1 \
--outputdir ${OFFLINEDIR_CPFS}

# Watson Knowledge Catalog
cloudctl case save \
--repo ${CASE_REPO_PATH} \
--case ibm-wkc \
--version 4.0.5 \
--outputdir ${OFFLINEDIR}
```


#### IBM Foundation Common services 
```
Check if, opencloud-operators catalog source already exists on your cluster.
oc get catalogsource -n openshift-marketplace opencloud-operators

cloudctl case launch \
  --case ${OFFLINEDIR_CPFS}/ibm-cp-common-services-1.10.1.tgz \
  --inventory ibmCommonServiceOperatorSetup \
  --namespace openshift-marketplace \
  --action install-catalog \
    --args "--registry icr.io --inputDir ${OFFLINEDIR_CPFS} --recursive"

# Check Status
oc get catalogsource -n openshift-marketplace opencloud-operators \
-o jsonpath='{.status.connectionState.lastObservedState} {"\n"}'
```

#### Cloud Pak for Data
```
cloudctl case launch \
  --case ${OFFLINEDIR}/ibm-cp-datacore-2.0.10.tgz \
  --inventory cpdPlatformOperator \
  --namespace openshift-marketplace \
  --action install-catalog \
    --args "--inputDir ${OFFLINEDIR} --recursive"

# Check Status
oc get catalogsource -n openshift-marketplace cpd-platform \
-o jsonpath='{.status.connectionState.lastObservedState} {"\n"}'
```


#### Watson Knowledge Catalog
```
cloudctl case launch \
  --case ${OFFLINEDIR}/ibm-wkc-4.0.5.tgz \
  --inventory wkcOperatorSetup \
  --namespace openshift-marketplace \
  --action install-catalog \
    --args "--inputDir ${OFFLINEDIR} --recursive"

# Check Status
oc get catalogsource -n openshift-marketplace ibm-cpd-wkc-operator-catalog \
-o jsonpath='{.status.connectionState.lastObservedState} {"\n"}'
```


***
#### 4.0 OpenShift cluster Setup
***

#### OpenShift Version
```
OpenShift version 4.6.30+ or 4.8.x are supported versions


oc get clusterversion
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.8.26    True        False         13d     Cluster version is 4.8.26


If the cluster is in olderversion
```


#### [Setup Persistent Storage and Storage Classes](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=tasks-setting-up-shared-persistent-storage)


Red Hat OpenShift Container Storage, IBM Spectrum® Scale Container Native, Portworx and NFS are supported storage types

```
# Sample output
oc get storageclass

NAME                            PROVISIONER                             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
localblock-sc                   kubernetes.io/no-provisioner            Delete          WaitForFirstConsumer   false                  25d
managed-nfs-storage (default)   nfs-provisioner/nfs                     Delete          Immediate              false                  25d
ocs-storagecluster-ceph-rbd     openshift-storage.rbd.csi.ceph.com      Delete          Immediate              true                   25d
ocs-storagecluster-ceph-rgw     openshift-storage.ceph.rook.io/bucket   Delete          Immediate              false                  25d
ocs-storagecluster-cephfs       openshift-storage.cephfs.csi.ceph.com   Delete          Immediate              true                   25d
openshift-storage.noobaa.io     openshift-storage.noobaa.io/obc         Delete          Immediate              false                  25d
```

#### Node Configurations
cloud Pak for Data has the following Node configuration requirements

* [ ] HAProxy timeout settings for the load balancer
```
timeout client          300s 
timeout server          300s 
```

* [ ] CRI-O container settings

```
scp core@$node:/etc/crio/crio.conf /tmp/crio.conf

……
[crio.runtime]
default_ulimits = [
        "nofile=66560:66560"
]
……

……
# Maximum number of processes allowed in a container.
pids_limit = 12288
……


cat << EOF | oc apply -f -
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker
  name: 99-worker-cp4d-crio-conf
spec:
  config:
    ignition:
      version: 3.1.0
    storage:
      files:
      - contents:
          source: data:text/plain;charset=utf-8;base64,$(cat /tmp/crio.conf | base64 -w0)
        filesystem: root
        mode: 0644
        path: /etc/crio/crio.conf
EOF

watch oc get nodes

NAME                              STATUS                     ROLES    AGE   VERSION
master0.aimlops.cp.fyre.ibm.com   Ready                      master   25d   v1.21.6+bb8d50a
master1.aimlops.cp.fyre.ibm.com   Ready                      master   25d   v1.21.6+bb8d50a
master2.aimlops.cp.fyre.ibm.com   Ready                      master   25d   v1.21.6+bb8d50a
worker0.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a
worker1.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a
worker2.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a
worker3.aimlops.cp.fyre.ibm.com   Ready,SchedulingDisabled   worker   25d   v1.21.6+bb8d50a
worker4.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a
worker5.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a
worker6.aimlops.cp.fyre.ibm.com   Ready                      worker   25d   v1.21.6+bb8d50a


watch oc get mcp
NAME     CONFIG                                             UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
master   rendered-master-9d063ba899f6aff6e80d3648cace54d9   True      False      False      3              3                   3                     0                      25d
worker   rendered-worker-59453b325bf987456cb9ab789e96a8c3   False     True       False      7              0                   0                     0                      25d

```

* [ ] Kernel parameter settings
```
cat << EOF | oc apply -f -
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  name: db2u-kubelet
spec:
  machineConfigPoolSelector:
    matchLabels:
      db2u-kubelet: sysctl
  kubeletConfig:
    allowedUnsafeSysctls:
      - "kernel.msg*"
      - "kernel.shm*"
      - "kernel.sem"
EOF

oc label machineconfigpool worker db2u-kubelet=sysctl

oc get machineconfigpool
```




***
#### 5.0 Project 
***

#### Create project namespaces for Cloud Pak for Data Installations
```
oc project cpd
oc project ibm-common-services
```
#### OperatorGroup

```
cat <<EOF |oc apply -f -
apiVersion: operators.coreos.com/v1alpha2
kind: OperatorGroup
metadata:
  name: operatorgroup
  namespace: ibm-common-services
spec:
  targetNamespaces:
  - ibm-common-services
EOF
```



***
#### 6.0 Installing IBM Cloud Pak Foundational Services
***

```
cat <<EOF |oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: ibm-common-service-operator
  namespace: ibm-common-services
spec:
  channel: v3
  installPlanApproval: Automatic
  name: ibm-common-service-operator
  source: opencloud-operators
  sourceNamespace: openshift-marketplace
EOF


$ oc --namespace ibm-common-services get csv
NAME                                           DISPLAY                                VERSION   REPLACES                                       PHASE
ibm-common-service-operator.v3.14.1            IBM Cloud Pak foundational services    3.14.1    ibm-common-service-operator.v3.14.0            Succeeded
ibm-namespace-scope-operator.v1.8.0            IBM NamespaceScope Operator            1.8.0     ibm-namespace-scope-operator.v1.7.0            Succeeded
operand-deployment-lifecycle-manager.v1.12.0   Operand Deployment Lifecycle Manager   1.12.0    operand-deployment-lifecycle-manager.v1.11.0   Succeeded


$ oc get crd | grep operandrequest
operandrequests.operator.ibm.com                                  2022-01-06T05:53:19Z

$ oc api-resources --api-group operator.ibm.com

NAME                SHORTNAMES   APIVERSION                  NAMESPACED   KIND
certmanagers                     operator.ibm.com/v1alpha1   false        CertManager
commonservices                   operator.ibm.com/v3         true         CommonService
namespacescopes     nss          operator.ibm.com/v1         true         NamespaceScope
operandbindinfos    opbi         operator.ibm.com/v1alpha1   true         OperandBindInfo
operandconfigs      opcon        operator.ibm.com/v1alpha1   true         OperandConfig
operandregistries   opreg        operator.ibm.com/v1alpha1   true         OperandRegistry
operandrequests     opreq        operator.ibm.com/v1alpha1   true         OperandRequest
podpresets                       operator.ibm.com/v1alpha1   true         PodPreset


```


***
#### 6.0 Installing IBM Cloud Pak for Data
***

```
#  Creating an operator subscription for the IBM Cloud Pak for Data platform operator
cat <<EOF |oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: cpd-operator
  namespace: ibm-common-services    #  Pick the project where you want to install the Cloud Pak for Data platform operator
spec:
  channel: v2.0
  installPlanApproval: Automatic
  name: cpd-platform-operator
  source: cpd-platform
  sourceNamespace: openshift-marketplace
EOF


# Check Status
oc get sub -n ibm-common-services cpd-operator \
-o jsonpath='{.status.installedCSV} {"\n"}'

oc get csv -n ibm-common-services cpd-platform-operator.v2.0.6 \
-o jsonpath='{ .status.phase } : { .status.message} {"\n"}'

oc get deployments -n ibm-common-services -l olm.owner="cpd-platform-operator.v2.0.6" \
-o jsonpath="{.items[0].status.availableReplicas} {'\n'}"

#  Enabling services to use namespace scoping with third-party operators
oc patch NamespaceScope common-service \
-n ibm-common-services \
--type=merge \
--patch='{"spec": {"csvInjector": {"enable": true} } }'

```

#### Watson Knowledge Catalog Subscription
```
cat <<EOF |oc apply -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  labels:
    app.kubernetes.io/instance:  ibm-cpd-wkc-operator-catalog-subscription
    app.kubernetes.io/managed-by: ibm-cpd-wkc-operator
    app.kubernetes.io/name:  ibm-cpd-wkc-operator-catalog-subscription
  name: ibm-cpd-wkc-operator-catalog-subscription
  namespace: ibm-common-services    # Pick the project that contains the Cloud Pak for Data operator
spec:
    channel: v1.0
    installPlanApproval: Automatic
    name: ibm-cpd-wkc
    source: ibm-cpd-wkc-operator-catalog
    sourceNamespace: openshift-marketplace
EOF

oc get sub -n ibm-common-services ibm-cpd-wkc-operator-catalog-subscription \
-o jsonpath='{.status.installedCSV} {"\n"}'

oc get csv -n ibm-common-services ibm-cpd-wkc.v1.0.5 \
-o jsonpath='{ .status.phase } : { .status.message} {"\n"}'

oc get deployments -n ibm-common-services -l olm.owner="ibm-cpd-wkc.v1.0.5" \
-o jsonpath="{.items[0].status.availableReplicas} {'\n'}"

```

***
#### Creating the custom security context constraint for Watson Knowledge Catalog
***

Update the Name space of the CPD to create the SCC
```
cat <<EOF |oc apply -f -
allowHostDirVolumePlugin: false
allowHostIPC: false
allowHostNetwork: false
allowHostPID: false
allowHostPorts: false
allowPrivilegeEscalation: true
allowPrivilegedContainer: false
allowedCapabilities: null
apiVersion: security.openshift.io/v1
defaultAddCapabilities: null
fsGroup:
  type: RunAsAny
kind: SecurityContextConstraints
metadata:
  annotations:
    kubernetes.io/description: WKC/IIS provides all features of the restricted SCC
      but runs as user 10032.
  name: wkc-iis-scc
readOnlyRootFilesystem: false
requiredDropCapabilities:
- KILL
- MKNOD
- SETUID
- SETGID
runAsUser:
  type: MustRunAs
  uid: 10032
seLinuxContext:
  type: MustRunAs
supplementalGroups:
  type: RunAsAny
volumes:
- configMap
- downwardAPI
- emptyDir
- persistentVolumeClaim
- projected
- secret
users:
- system:serviceaccount:cpd:wkc-iis-sa
EOF

```

***
#### Installation of Cloud Pak for Data
***

```
cat <<EOF |oc apply -f -
apiVersion: operator.ibm.com/v1alpha1
kind: OperandRequest
metadata:
  name: empty-request
  namespace: cpd        # Replace with the project where you will install Cloud Pak for Data
spec:
  requests: []
EOF



cat <<EOF |oc apply -f -
apiVersion: cpd.ibm.com/v1
kind: Ibmcpd
metadata:
  name: ibmcpd-cr                        # This is the recommended name, but you can change it
  namespace: cpd                # Replace with the project where you will install Cloud Pak for Data
spec:
  license:
    accept: true
    license: Enterprise         # Specify the Cloud Pak for Data license you purchased
  storageVendor: ocs
  
EOF

# Check status
$ oc get Ibmcpd ibmcpd-cr -o jsonpath="{.status.controlPlaneStatus}{'\n'}"
Completed

$ oc get ZenService lite-cr -o jsonpath="{.status.zenStatus}{'\n'}"
Completed

# Wait for install to complete
$ watch "oc get pods -n cpd"

NAME                          READY   STATUS	  RESTARTS   AGE
create-secrets-job-lzmft      0/1     Completed   0          3m27s
usermgmt-7b6b579d66-nc64t     0/1     Running     0          57s
usermgmt-7b6b579d66-r5cnt     0/1     Running     0          57s
zen-metastoredb-0             1/1     Running     0          2m37s
zen-metastoredb-1             1/1     Running     0          2m37s
zen-metastoredb-2             1/1     Running     0          2m37s
zen-metastoredb-certs-xhggr   0/1     Completed   0          2m51s
zen-metastoredb-init-wcrq6    0/1     Completed   0          2m39s

# Get CPD URL
$ oc get ZenService lite-cr -o jsonpath="{.status.url}{'\n'}"

cpd-cpd.apps.aimlops.cp.fyre.ibm.com

# password
$ oc extract secret/admin-user-details --keys=initial_admin_password --to=-
```


***
#### Installation of WKC
***

```
cat <<EOF |oc apply -f -
apiVersion: wkc.cpd.ibm.com/v1beta1
kind: WKC
metadata:
  name: wkc-cr     # This is the recommended name, but you can change it
  namespace: cpd     # Replace with the project where you will install Watson Knowledge Catalog
spec:
  license:
    accept: true
    license: Enterprise     # Specify the license you purchased.
  version: 4.0.5
  storageVendor: ocs
  # wkc_db2u_set_kernel_params: True
  # iis_db2u_set_kernel_params: True
  # install_wkc_core_only: true     # To install the core version of the service, remove the comment tagging from the beginning of the line.
EOF


# Check Status
# All these components takes 3 hours to complete

$ oc get WKC wkc-cr -o jsonpath='{.status.wkcStatus} {"\n"}'
$ oc get CCS ccs-cr -o jsonpath='{.status.ccsStatus} {"\n"}'
$ oc get DataRefinery datarefinery-sample -o jsonpath='{.status.datarefineryStatus} {"\n"}'
$ oc get Db2aaserviceService db2aaservice-cr -o jsonpath='{.status.db2aaserviceStatus} {"\n"}'
$ oc get IIS iis-cr -o jsonpath='{.status.iisStatus} {"\n"}'
$ oc get UG ug-cr -o jsonpath='{.status.ugStatus} {"\n"}'
